{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекуррентные нейронные сети\n",
    "\n",
    "Рекуррентные нейронные сети работают с информацией, в которой есть последовательность,где текущее значение данных зависит от предыдущего.\n",
    "\n",
    "В этом видео мы будем работать с аудио данными, используя LSTM.\n",
    "\n",
    "Этот ноутбук и датасеты доступны в моем Github репозитории:\n",
    "```\n",
    "git clone https://github.com/andreiliphd/reinforcement-content.git\n",
    "```\n",
    "\n",
    "Если нет Git, то его нужно установить.\n",
    "\n",
    "Linux:\n",
    "```\n",
    "sudo apt-get update\n",
    "sudo apt-get install git\n",
    "```\n",
    "\n",
    "Windows: скачайте Git с сайта [git-scm.com](https://git-scm.com/download/win).\n",
    "\n",
    "Если вы нашли ошибку на сайте, ее можно исправить самостоятельно сделав Pull Request в Git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовительный этап\n",
    "\n",
    "Нам нужно установить зависимости прежде чем начать работу.\n",
    "Выполните команды:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge sox\n",
    "```\n",
    "\n",
    "и\n",
    "\n",
    "```\n",
    "conda install -c pytorch torchaudio\n",
    "```\n",
    "\n",
    "Этими командами мы установим `torchaudio`, которая является библиотекой от Facebook для работы со звуком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Этапы решения задачи\n",
    "\n",
    "1. Загрузка и аугментация данных.\n",
    "2. Декларирование модели.\n",
    "3. Инстанциирование модели.\n",
    "4. Инстанциирование функции потерь(лосс).\n",
    "5. Инстанциирование оптимизатора.\n",
    "6. Создание тренировочной петли(лупа)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и аугментация данных\n",
    "\n",
    "Какие проблемы перед нами стоят:\n",
    "1. В `torchaudio` нет готового класса для загрузки аудио.\n",
    "2. Аудио нужно конвертировать в MFCC для того, чтобы извлечь черты.\n",
    "3. Нужно изменить форму данных в нашем загрузчике, чтобы отвечать формату [batch, seq_len, input_size].\n",
    "4. Чтобы использовать такой формат при создании LSTM нужно указать `batch_first=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "class VoiceDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, root):\n",
    "        super(VoiceDataset, self).__init__()\n",
    "        self.root = root\n",
    "        self.files = glob.glob(root + '*/*') \n",
    "        classes, class_to_idx = self._find_classes(self.root)\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        waveform, sample_rate = torchaudio.load(self.files[index])\n",
    "        sample = torchaudio.transforms.MFCC(sample_rate=sample_rate)(waveform)\n",
    "        sample = sample.reshape(80,442)\n",
    "        target = self.class_to_idx[self.files[index].split('/')[2]]\n",
    "        \n",
    "        return sample, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    # the code below is taken from PyTorch source code DatasetFolder class by @andreiliphd\n",
    "    def _find_classes(self, dir):\n",
    "        if sys.version_info >= (3, 5):\n",
    "            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        else:\n",
    "            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы создать свой датасет, которым потом можно будет пользоваться в загрузчике нужно сделать класс `VoiceDataset` наследовать от `torch.utils.data.Dataset`, а также необходимо переопределить методы `__len__` и `__getitem__`. Метод `__len__` выдает количество данных(количество наших аудио файлов) и метод `__getitem__` по индексу загружает данных с диска. Есть встроенные датасеты для изображений в PyTorch, но в нашем случае пришлось идти длинной дорогой, так как датасет для аудио я не нашел. Такая же логика для любых данных, которые нативно не поддерживает PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = torch.utils.data.DataLoader(VoiceDataset('datasets/sound/'),batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передаем класс `VoiceDataset` в даталоадер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Декларирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=442, hidden_size=256,num_layers=3, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=20480, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.fc4 = nn.Linear(in_features=32, out_features=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.lstm1(x)[0])\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на `self.lstm1(x)[0]`, мы не берем скрытое состояние LSTM, так как нам наши данные независимы от друг друга. Каждый батч по отдельности. И каждый батч это один, два или три."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инстанциирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И перемещение ее на видеокарту для увеличения скорости обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инстанциирование функции потерь(лосс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартный лосс для задач классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инстанциирование оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание тренировочной петли(лупа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  1.065126657485962\n",
      "Training accuracy: 33%\n",
      "Epoch:  1 Loss:  1.1673775911331177\n",
      "Training accuracy: 40%\n",
      "Epoch:  2 Loss:  1.0520007610321045\n",
      "Training accuracy: 67%\n",
      "Epoch:  3 Loss:  0.9513782262802124\n",
      "Training accuracy: 67%\n",
      "Epoch:  4 Loss:  0.2251937985420227\n",
      "Training accuracy: 93%\n",
      "Epoch:  5 Loss:  0.4559391736984253\n",
      "Training accuracy: 100%\n",
      "Epoch:  6 Loss:  0.16064739227294922\n",
      "Training accuracy: 97%\n",
      "Epoch:  7 Loss:  0.031351327896118164\n",
      "Training accuracy: 100%\n",
      "Epoch:  8 Loss:  0.0012655258178710938\n",
      "Training accuracy: 100%\n",
      "Epoch:  9 Loss:  0.00048160552978515625\n",
      "Training accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for data, label in sound:\n",
    "        if torch.cuda.is_available():\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    print('Epoch: ', epoch, 'Loss: ', loss.item())\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for data, target in sound:\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        max_arg_output = torch.argmax(output, dim=1)\n",
    "        total_correct += int(torch.sum(max_arg_output == target))\n",
    "        total += data.shape[0]\n",
    "    print('Training accuracy: {:.0%}'.format(total_correct/total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "Рекуррентные сети обладают достаточно большой формулой, но принцип ее работы простой. Также просто делается рекуррентная модель. \n",
    "\n",
    "Записывайтесь на мой [курс](https://reinforcementlearning.ru/uslugi/individualnoe-obuchenie/), где я расскажу все более детально и подробно, а главное простыми словами. Для меня нет глупых вопросов, для меня нет начинающих, для меня есть желающие познать и я помогаю им в этом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
